{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-25T22:56:54.600372Z",
     "start_time": "2024-07-25T22:56:48.211128Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-25 23:56:51.796490: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodel\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstock_data\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m fetch_stock_data, preprocess_data \u001B[38;5;66;03m# model package contains useful model training functions\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmodel\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m create_model, create_sequences\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mjson_manage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m json_state, data_file \u001B[38;5;66;03m# edit the fastapi state, data file\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpreprocessing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MinMaxScaler\n",
      "File \u001B[0;32m~/Desktop/pycharm/fastApiProject1/model/model.py:10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mean_squared_error, mean_absolute_error, r2_score\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcallbacks\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m EarlyStopping, Callback\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Model\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlayers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LSTM, Dense, Input\n",
      "File \u001B[0;32m/opt/anaconda3/envs/fastApiProject1/lib/python3.11/site-packages/tensorflow/__init__.py:37\u001B[0m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_sys\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_typing\u001B[39;00m\n\u001B[0;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m module_util \u001B[38;5;28;01mas\u001B[39;00m _module_util\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlazy_loader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LazyLoader \u001B[38;5;28;01mas\u001B[39;00m _LazyLoader\n\u001B[1;32m     40\u001B[0m \u001B[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/fastApiProject1/lib/python3.11/site-packages/tensorflow/python/__init__.py:36\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtraceback\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;66;03m# import it in modules_with_exports.py instead.\u001B[39;00m\n\u001B[1;32m     32\u001B[0m \n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# go/tf-wildcard-import\u001B[39;00m\n\u001B[1;32m     34\u001B[0m \u001B[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001B[39;00m\n\u001B[0;32m---> 36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tensorflow \u001B[38;5;28;01mas\u001B[39;00m _pywrap_tensorflow\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m context\n\u001B[1;32m     39\u001B[0m \u001B[38;5;66;03m# pylint: enable=wildcard-import\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# Bring in subpackages.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/fastApiProject1/lib/python3.11/site-packages/tensorflow/python/pywrap_tensorflow.py:62\u001B[0m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;66;03m# pylint: disable=wildcard-import,g-import-not-at-top,line-too-long,undefined-variable\u001B[39;00m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 62\u001B[0m   \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pywrap_tensorflow_internal\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;241m*\u001B[39m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;66;03m# This try catch logic is because there is no bazel equivalent for py_extension.\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;66;03m# Externally in opensource we must enable exceptions to load the shared object\u001B[39;00m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;66;03m# by exposing the PyInit symbols with pybind. This error will only be\u001B[39;00m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;66;03m# caught internally or if someone changes the name of the target _pywrap_tensorflow_internal.\u001B[39;00m\n\u001B[1;32m     67\u001B[0m \n\u001B[1;32m     68\u001B[0m \u001B[38;5;66;03m# This logic is used in other internal projects using py_extension.\u001B[39;00m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mModuleNotFoundError\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from model.stock_data import fetch_stock_data, preprocess_data # model package contains useful model training functions\n",
    "from model.model import create_model, create_sequences\n",
    "from json_manage import json_state, data_file # edit the fastapi state, data file\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import DataFrame as DF\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "cwd = os.getenv(\"CWD\")\n",
    "print(cwd)\n",
    "\n",
    "#fastapi_process = subprocess.Popen([\"uvicorn\", \"main:app\", \"--reload\"], cwd=cwd)\n",
    "#streamlit_process = subprocess.Popen([\"streamlit\", \"run\", \"streamlit/app.py\"])\n",
    "\n",
    "json_state.set_state(\"training\")\n",
    "\n",
    "ticker_name = \"NVDA\"\n",
    "time_period = 31 # days used to create sliding window\n",
    "\n",
    "# Fetch and preprocess data\n",
    "try:\n",
    "    print(\"Fetching stock data\")\n",
    "    data = fetch_stock_data(ticker_name)\n",
    "    data = preprocess_data(data)\n",
    "except:\n",
    "    print(\"Error - stock data\")\n",
    "    sys.exit()\n",
    "\n",
    "#data.plot.line(y='Close', use_index=True)\n",
    "#plt.show()\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_data = DF(scaler.fit_transform(data), columns=data.columns)\n",
    "\n",
    "#ic(scaled_data.head())\n",
    "\n",
    "predictors = list(data.columns)\n",
    "train = [\"+1d\",\"+7d\"]\n",
    "\n",
    "for col in train:\n",
    "    predictors.remove(col)\n",
    "\n",
    "\n",
    "predictors_scaled_df = scaled_data[predictors]\n",
    "train_scaled_df = scaled_data[train]\n",
    "\n",
    "print(predictors_scaled_df.head(), train_scaled_df.head())\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(np.array(predictors_scaled_df), np.array(train_scaled_df),\n",
    "                                                    test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "x_train_sequences = create_sequences(x_train, time_period)\n",
    "y_train_sequences = create_sequences(y_train, time_period)\n",
    "x_test_sequences = create_sequences(x_test, time_period)\n",
    "y_test_sequences = create_sequences(y_test, time_period)\n",
    "\n",
    "print(x_train_sequences.shape, y_train_sequences.shape)\n",
    "\n",
    "input_shape = x_train_sequences.shape # samples, timesteps, features\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "model = create_model(input_shape)\n",
    "\n",
    "model_info = model.fit(x_train_sequences, [y_train_sequences[:, :, 0], y_train_sequences[:, :, 1]],\n",
    "                    epochs=25,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2,\n",
    "                    validation_data=(x_test_sequences, [y_test_sequences[:, :, 0], y_test_sequences[:, :, 1]]),\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "model.save(\"stock_1,7day_model.keras\")\n",
    "\n",
    "\n",
    "y_test_result = model.predict(x_test_sequences)\n",
    "\n",
    "# `y_test_result` will be a list of two arrays, each containing the predictions for one of the outputs\n",
    "y_test_result_1d = y_test_result[0]  # Predictions for +1d\n",
    "y_test_result_7d = y_test_result[1]  # Predictions for +7d\n",
    "\n",
    "y_test_sequences_reduced = y_test_sequences[:, -1, :] # reduce the sequence dimension, take +1d and +7d at last index\n",
    "\n",
    "# Calculate accuracy metrics\n",
    "y_test_actual_1d = y_test_sequences_reduced[:, 0]  # Actual values for +1d from the test set\n",
    "y_test_actual_7d = y_test_sequences_reduced[:, 1]  # Actual values for +7d from the test set\n",
    "\n",
    "mse_1d = mean_squared_error(y_test_actual_1d, y_test_result_1d)\n",
    "mae_1d = mean_absolute_error(y_test_actual_1d, y_test_result_1d)\n",
    "r2_1d = r2_score(y_test_actual_1d, y_test_result_1d)\n",
    "\n",
    "mse_7d = mean_squared_error(y_test_actual_7d, y_test_result_7d)\n",
    "mae_7d = mean_absolute_error(y_test_actual_7d, y_test_result_7d)\n",
    "r2_7d = r2_score(y_test_actual_7d, y_test_result_7d)\n",
    "\n",
    "print(f'+1d - MSE: {mse_1d:.3e}, MAE: {mae_1d:.3e}, R2: {r2_1d:.3f}')\n",
    "print(f'+7d - MSE: {mse_7d:.3e}, MAE: {mae_7d:.3e}, R2: {r2_7d:.3f}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "json_state.set_state(\"trained\")\n",
    "\n",
    "\n",
    "# pause until the processes terminate\n",
    "#fastapi_process.wait()\n",
    "#streamlit_process.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming y_test_result and y_test_sequences_reduced are already defined\n",
    "\n",
    "\n",
    "# Flatten the predictions and actual values to align them for comparison\n",
    "y_test_result_1d_flat = y_test_result_1d.flatten()\n",
    "y_test_result_7d_flat = y_test_result_7d.flatten()\n",
    "y_test_actual_1d_flat = y_test_actual_1d.flatten()\n",
    "y_test_actual_7d_flat = y_test_actual_7d.flatten()\n",
    "\n",
    "# Plot +1d predictions vs actual values\n",
    "plt.figure(figsize=(14, 7))\n",
    "\n",
    "plt.subplot(2, 1, 1)  # 2 rows, 1 column, 1st subplot\n",
    "plt.plot(y_test_actual_1d_flat, label='Actual +1d')\n",
    "plt.plot(y_test_result_1d_flat, label='Predicted +1d', linestyle='--')\n",
    "plt.title('Predicted vs Actual Stock Prices for +1d')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Normalized Price')\n",
    "plt.legend()\n",
    "\n",
    "# Plot +7d predictions vs actual values\n",
    "plt.subplot(2, 1, 2)  # 2 rows, 1 column, 2nd subplot\n",
    "plt.plot(y_test_actual_7d_flat, label='Actual +7d')\n",
    "plt.plot(y_test_result_7d_flat, label='Predicted +7d', linestyle='--')\n",
    "plt.title('Predicted vs Actual Stock Prices for +7d')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Normalized Price')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T22:56:56.062593Z",
     "start_time": "2024-07-25T22:56:56.002401Z"
    }
   },
   "id": "d794e0ffb8981c7c"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_result_1d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 8\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Assuming y_test_result and y_test_sequences_reduced are already defined\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \n\u001B[1;32m      6\u001B[0m \n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m# Flatten the predictions and actual values to align them for comparison\u001B[39;00m\n\u001B[0;32m----> 8\u001B[0m y_test_result_1d_flat \u001B[38;5;241m=\u001B[39m y_test_result_1d\u001B[38;5;241m.\u001B[39mflatten()\n\u001B[1;32m      9\u001B[0m y_test_result_7d_flat \u001B[38;5;241m=\u001B[39m y_test_result_7d\u001B[38;5;241m.\u001B[39mflatten()\n\u001B[1;32m     10\u001B[0m y_test_actual_1d_flat \u001B[38;5;241m=\u001B[39m y_test_actual_1d\u001B[38;5;241m.\u001B[39mflatten()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'y_test_result_1d' is not defined"
     ]
    }
   ],
   "source": [
    "# reconstruct actual and predicted values\n",
    "\n",
    "actual_stock_values = [y_test_actual_1d_flat, y_test_actual_7d_flat]\n",
    "\n",
    "predicted_stock_values = [y_test_result_1d_flat, y_test_result_7d_flat]\n",
    "\n",
    "print(np.array(actual_stock_values).shape, np.array(predicted_stock_values).shape)\n",
    "\n",
    "from json_manage import data_file\n",
    "from pandas import DataFrame as DF\n",
    "\n",
    "data_file.write(np.array(actual_stock_values), np.array(predicted_stock_values))\n",
    "\n",
    "recalled_test = DF(data_file.read())\n",
    "recalled_test.info()\n",
    "print(recalled_test.head(10))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T22:57:00.559205Z",
     "start_time": "2024-07-25T22:56:59.263169Z"
    }
   },
   "id": "1316fe2f83faa3cd"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_actual_1d_flat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# reconstruct actual and predicted values\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m actual_stock_values \u001B[38;5;241m=\u001B[39m [y_test_actual_1d_flat, y_test_actual_7d_flat]\n\u001B[1;32m      5\u001B[0m predicted_stock_values \u001B[38;5;241m=\u001B[39m [y_test_result_1d_flat, y_test_result_7d_flat]\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(np\u001B[38;5;241m.\u001B[39marray(actual_stock_values)\u001B[38;5;241m.\u001B[39mshape, np\u001B[38;5;241m.\u001B[39marray(predicted_stock_values)\u001B[38;5;241m.\u001B[39mshape)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'y_test_actual_1d_flat' is not defined"
     ]
    }
   ],
   "source": [
    "results_df = DF([y_test_result_1d_flat, y_test_result_7d_flat, y_test_actual_1d_flat, y_test_actual_7d_flat]).T\n",
    "#results_df.to_csv('data.csv', header=['Result 1d', 'Result 7d', 'Real 1d', 'Real 7d'])\n",
    "results_df.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T22:57:01.669258Z",
     "start_time": "2024-07-25T22:57:01.577026Z"
    }
   },
   "id": "a0b8a34cbe0f9a9d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m results_df \u001B[38;5;241m=\u001B[39m DF([y_test_result_1d_flat, y_test_result_7d_flat, y_test_actual_1d_flat, y_test_actual_7d_flat])\u001B[38;5;241m.\u001B[39mT\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m#results_df.to_csv('data.csv', header=['Result 1d', 'Result 7d', 'Real 1d', 'Real 7d'])\u001B[39;00m\n\u001B[1;32m      3\u001B[0m results_df\u001B[38;5;241m.\u001B[39mhead(\u001B[38;5;241m10\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'DF' is not defined"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-25T22:57:03.914857Z",
     "start_time": "2024-07-25T22:57:03.862042Z"
    }
   },
   "id": "e5cf44b4f4382077"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
